# TechJam Project

A full-stack application combining a modern React frontend with a powerful LangGraph-powered AI backend.

## ğŸš€ Project Overview

TechJam is a comprehensive project that demonstrates the integration of:
- **Frontend**: Modern React application with TypeScript and Vite
- **Backend**: LangGraph-powered AI workflows with FastAPI
- **AI Integration**: LangChain and OpenAI for intelligent conversations

## ğŸ“ Project Structure

```
TechJam/
â”œâ”€â”€ frontend/           # React frontend application
â”‚   â”œâ”€â”€ src/           # Source code
â”‚   â”œâ”€â”€ package.json   # Frontend dependencies
â”‚   â””â”€â”€ README.md      # Frontend documentation
â”œâ”€â”€ langgraph/         # LangGraph backend API
â”‚   â”œâ”€â”€ main.py        # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt # Python dependencies
â”‚   â””â”€â”€ README.md      # Backend documentation
â””â”€â”€ README.md          # This file
```

## ğŸ› ï¸ Technology Stack

### Frontend
- **React 18** - Modern React with concurrent features
- **TypeScript** - Type-safe development
- **Vite** - Lightning-fast build tool
- **Modern CSS** - Beautiful, responsive design

### Backend
- **FastAPI** - High-performance async API framework
- **LangGraph** - AI workflow orchestration
- **LangChain** - LLM integration and tools
- **OpenAI** - Advanced language models

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** (version 16 or higher)
- **Python** (version 3.8 or higher)
- **OpenAI API Key** (for AI functionality)

### Frontend Setup

1. Navigate to the frontend directory:
   ```bash
   cd frontend
   ```

2. Install dependencies:
   ```bash
   npm install
   ```

3. Start the development server:
   ```bash
   npm run dev
   ```

4. Open your browser and visit `http://localhost:3000`

### Backend Setup

1. Navigate to the langgraph directory:
   ```bash
   cd langgraph
   ```

2. Create a virtual environment:
   ```bash
   python -m venv venv
   
   # On Windows
   venv\Scripts\activate
   
   # On macOS/Linux
   source venv/bin/activate
   ```

3. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file with your OpenAI API key:
   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   ```

5. Start the backend server:
   ```bash
   python main.py
   ```

6. The API will be available at `http://localhost:8000`

## ğŸ”— API Integration

The frontend and backend are designed to work together seamlessly:

- **Frontend**: Runs on `http://localhost:3000`
- **Backend**: Runs on `http://localhost:8000`
- **CORS**: Configured for cross-origin requests
- **API Documentation**: Available at `http://localhost:8000/docs`

## ğŸ¯ Features

### Frontend Features
- âš¡ **Vite** - Lightning fast development
- âš›ï¸ **React 18** - Latest React features
- ğŸ”· **TypeScript** - Type safety
- ğŸ¨ **Modern UI** - Beautiful, responsive design
- ğŸ”§ **ESLint** - Code quality
- ğŸ“¦ **Hot Reload** - Instant updates

### Backend Features
- ğŸ¤– **LangGraph Workflows** - Complex AI conversation flows
- ğŸš€ **FastAPI** - High-performance API
- ğŸ”— **LangChain Integration** - LLM ecosystem
- ğŸ’¬ **Conversation Management** - Track conversations
- ğŸ¯ **Sentiment Analysis** - Built-in analysis
- ğŸ“Š **Health Monitoring** - Service health checks

## ğŸ§ª Testing the Integration

1. Start both frontend and backend servers
2. Open the frontend at `http://localhost:3000`
3. The frontend can make API calls to the backend
4. Test the chat functionality through the API

## ğŸ“š Documentation

- **Frontend Documentation**: See `frontend/README.md`
- **Backend Documentation**: See `langgraph/README.md`
- **API Documentation**: Visit `http://localhost:8000/docs` when backend is running

## ğŸ”§ Development

### Frontend Development
```bash
cd frontend
npm run dev          # Start development server
npm run build        # Build for production
npm run lint         # Run ESLint
npm run preview      # Preview production build
```

### Backend Development
```bash
cd langgraph
python main.py       # Start development server
# or
uvicorn main:app --reload  # Start with auto-reload
```

## ğŸš€ Deployment

### Frontend Deployment
1. Build the frontend: `npm run build`
2. Deploy the `dist` folder to your hosting service

### Backend Deployment
1. Set up production environment variables
2. Use a production ASGI server like Gunicorn
3. Configure reverse proxy (nginx)
4. Set up monitoring and logging

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

If you encounter any issues:

1. Check the individual README files in `frontend/` and `langgraph/`
2. Ensure all prerequisites are installed
3. Verify environment variables are set correctly
4. Check that both servers are running on the correct ports

## ğŸ‰ Getting Started with AI

To start using the AI features:

1. Get an OpenAI API key from [OpenAI](https://platform.openai.com/)
2. Add it to your `.env` file in the langgraph directory
3. Start the backend server
4. Test the chat endpoint at `http://localhost:8000/chat`

The LangGraph workflow will process your messages and provide intelligent responses with sentiment analysis!
